#ifndef _H_TIRAMISU_CORE_
#define _H_TIRAMISU_CORE_

#include <isl/set.h>
#include <isl/map.h>
#include <isl/union_map.h>
#include <isl/union_set.h>
#include <isl/ast_build.h>
#include <isl/schedule.h>
#include <isl/schedule_node.h>
#include <isl/space.h>

#include <map>
#include <string.h>
#include <stdint.h>

#include <Halide.h>
#include <tiramisu/debug.h>
#include <tiramisu/expr.h>
#include <tiramisu/type.h>

namespace tiramisu
{

class function;
class computation;
class buffer;
class constant;

/**
  * Add a dimension to the range of a map in the specified position.
  * Assume that the name of the new dimension is equal to the name of the corresponding
  * dimension in the domain of the map.
  * Add a constraint that indicates that the added dim is equal to a constant.
  */
isl_map *isl_map_add_dim_and_eq_constraint(isl_map *map, int dim_pos, int constant);

struct HalideCodegenOutput {
    std::map<std::string, tiramisu::computation *> computation_list;
    std::map<std::string, tiramisu::constant *> constant_list;
    std::map<std::string, tiramisu::buffer *> output_buffers;

    HalideCodegenOutput(const std::map<std::string, tiramisu::computation *> &computations,
                        const std::map<std::string, tiramisu::constant *> &constants,
                        const std::map<std::string, tiramisu::buffer *> &buffers)
        : computation_list(computations), constant_list(constants), output_buffers(buffers) {}
};

HalideCodegenOutput halide_pipeline_to_tiramisu_function(
    Halide::Internal::Stmt s,
    const std::vector<Halide::Internal::Function> &outputs,
    const std::map<std::string, Halide::Internal::Function> &env,
    const std::map<std::string, std::vector<int32_t>> &output_buffers_size,
    tiramisu::function *func);

void halide_pipeline_to_c(
    Halide::Internal::Stmt s,
    const std::vector<Halide::Internal::Function> &outputs,
    const std::map<std::string, Halide::Internal::Function> &env,
    const std::map<std::string, std::vector<int32_t>> &output_buffers_size,
    const std::string &func);

#define LET_STMT_PREFIX "_tiramisu_"


/**
  * A class to represent functions.  A function is composed of
  * computations (of type tiramisu::computation).
  */
class function
{
private:
    /**
      * The name of the function.
      */
    std::string name;

    /**
      * Function arguments.  These are the buffers or scalars that are
      * passed to the function.
      */
    std::vector<tiramisu::buffer *> function_arguments;

    /**
      * A vector representing the invariants of the function (symbolic
      * constants or variables that are invariant to the function i.e.
      * do not change their value during the execution of the function).
      */
    std::vector<tiramisu::constant> invariants;

    /**
      * An ISL context associate with the function.
      */
    isl_ctx *ctx;

    /**
      * An ISL AST representation of the function.
      * The ISL AST is generated by calling gen_isl_ast().
      */
    isl_ast_node *ast;

    /**
      * A vector representing the parallel dimensions around
      * the computations of the function.
      * A parallel dimension is identified using the pair
      * <computation_name, level>, for example the pair
      * <S0, 0> indicates that the loop with level 0
      * (i.e. the outermost loop) around the computation S0
      * should be parallelized.
      */
    std::vector<std::pair<std::string, int>> parallel_dimensions;

    /**
      * A vector representing the vectorized dimensions around
      * the computations of the function.
      * A vector dimension is identified using the pair
      * <computation_name, level>, for example the pair
      * <S0, 0> indicates that the loop with level 0
      * (i.e. the outermost loop) around the computation S0
      * should be vectorized.
      */
    std::vector<std::pair<std::string, int>> vector_dimensions;

    /**
      * A vector representing the GPU dimensions around
      * the computations of the function.
      * GPU dimensions are dimensions that should be mapped
      * to parallel GPU threads.
      * GPU dimensions are identified using the tuple
      * <computation_name, level0, level1>, for example the tuple
      * <S0, 0, 1> indicates that the loops with levels 0 and 1
      * (i.e. the two outermost loops) around the computation S0
      * should be mapped to GPU.
      * Level1 must be the level following level0, i.e.
      * level1 == level0 + 1
      */
    std::vector<std::pair<std::string, std::pair<int, int>>> gpu_dimensions;


    /**
      * Body of the function (a vector of computations).
      * The order of the computations in the vector does not have any
      * effect on the actual order of execution of the computations.
      * The order of execution of computations is specified through the
      * schedule.
      */
    std::vector<computation *> body;

    /**
      * A Halide statement that represents the whole function.
      * This value stored in halide_stmt is generated by the code generator
      * and is empty before calling the code generator.
      */
    Halide::Internal::Stmt *halide_stmt;

    /**
      * A map representing the buffers of the function.  Some of these
      * buffers are passed to the function as arguments and some are
      * declared and allocated within the function itself.
      */
    std::map<std::string, tiramisu::buffer *> buffers_list;

    /**
     * The context set of the function.  i.e. a set representing the
     * constraints over the parameters.
     * The parameters of a function are the function invariants (constants).
     */
    isl_set *context_set;

    /**
     * The names of the iterators.
     */
    std::vector<std::string> iterator_names;

public:

    /**
     * Construct a function with the name \p name.
     */
    function(std::string name);

    /**
      * Get the arguments of the function.
      */
    const std::vector<tiramisu::buffer *> &get_arguments() const;

    /**
      * This function iterates over the computations of the function.
      * It modifies the identity schedule of each computation in order to
      * make all the identity schedules have the same number of dimensions
      * in their ranges.
      * This is done by adding dimensions equal to 0 to the range of each
      * identity schedule that does not have enough dimensions.
      */
    isl_union_map *get_aligned_identity_schedules() const;

    /**
      * Return a map that represents the buffers of the function.
      * The buffers of the function are buffers that are either passed
      * to the function as arguments or are buffers that are declared
      * and allocated within the function itself.
      * The names of the buffers are used as a key for the map.
      */
    const std::map<std::string, tiramisu::buffer *> &get_buffers() const;

    /**
      * Return a vector of the computations of the function.
      * The order of the computations in the vector does not have any
      * effect on the actual order of execution of the computations.
      * The order of execution of computations is specified through the
      * schedule.
      */
    const std::vector<computation *> get_computations() const;

    /**
      * Return the computation of the function that has
      * the name \p str.
      */
    computation *get_computation_by_name(std::string str) const;

    /**
      * Return a set that represents the parameters of the function
      * (an ISL set that represents the parameters and constraints over
      * the parameters of the functions,  a parameter is an invariant
      * of the function). This set is also known as the context of
      * the program.
      * An example of a context set is the following:
      *          "[N,M]->{: M>0 and N>0}"
      * This context set indicates that the two parameters N and M
      * are strictly positive.
      */
     isl_set *get_parameter_set() const;

     /**
       * Return the isl_ctx associated with this function.
       * This is an ISL specific object required when calling certain
       * ISL functions.  It does not represent the set of parameters
       * of the function (which should be retrieved by calling
       * get_parameter_set()).
       */
     isl_ctx *get_ctx() const;

    /**
      * Get the name of the function.
      */
    const std::string &get_name() const;

    /**
      * Return a vector representing the invariants of the function
      * (symbolic constants or variables that are invariant to the
      * function i.e. do not change their value during the execution
      * of the function).
      */
    const std::vector<tiramisu::constant> &get_invariants() const;

    /**
      * Return the Halide statement that represents the whole
      * function.
      * The Halide statement is generated by the code generator.
      * This function should not be called before calling the code
      * generator.
      */
    Halide::Internal::Stmt get_halide_stmt() const;

    /**
     * This functions iterates over the schedules of the function (the schedule
     * of each computation in the function) and computes the maximal dimension
     * among the dimensions of the ranges of all the schedules.
     */
    int get_max_schedules_range_dim() const;

    /**
      * This function first computes the identity schedules,
      * then it computes the maximal dimension among the dimensions
      * of the ranges of all the identity schedules.
      */
    int get_max_identity_schedules_range_dim() const;

    /**
      * Return the union of all the iteration domains
      * of the computations of the function.
      */
    isl_union_set *get_iteration_domain() const;

    /**
      * Return the union of all the schedules
      * of the computations of the function.
      */
    isl_union_map *get_schedule() const;

    /**
      * Return an ISL AST that represents this function.
      * This function itself does not generate the ISL AST, it just
      * returns it if it already exists.
      * The function gen_isl_ast() should be called before calling
      * this function.
      */
    isl_ast_node *get_isl_ast() const;

    /**
      * Return the union of time-processor domains of each
      * computation in the function.
      * In the time-processor representation, the logical time of
      * execution and the processor where the computation will be
      * executed are both specified.
      */
    isl_union_set *get_time_processor_domain() const;

    /**
    * Get the iterator names of the function.
    */
    const std::vector<std::string>& get_iterator_names() const;

    /**
       * Return a string representing the name of the GPU iterator at
       * dimension \p lev0.
       * This function only returns a non-empty string if the
       * computation \p comp is mapped to GPU at the dimension \p lev0.
       */
     std::string get_gpu_iterator(std::string comp, int lev0) const;

     /**
       * Return true if the computation \p comp should be parallelized
       * at the loop level \p lev.
       */
     bool should_parallelize(std::string comp, int lev) const;

     /**
       * Return true if the computation \p comp should be vectorized
       * at the loop level \p lev.
       */
     bool should_vectorize(std::string comp, int lev) const;

     /**
       * Return true if the computation \p comp should be mapped to GPU
       * at the loop levels \p lev0.
       */
     bool should_map_to_gpu(std::string comp, int lev0) const;

    /**
      * Add an invariant to the function.
      */
    void add_invariant(tiramisu::constant param);

    /**
      * Add a buffer to the function.
      * The buffers of the function are either:
      * - buffers passed to the function as arguments, or
      * - buffers that are declared and allocated within the function
      * itself.
      * The first element of the pair is the name of the buffer (it is
      * used as a key), the second element of the pair is a pointer
      * to the buffer.
      */
    void add_buffer(std::pair<std::string, tiramisu::buffer *> buf);

    /**
      * Add a computation to the function.  The order in which
      * computations are added to the function is not important.
      * The order of execution is specified using the schedule.
      * This doesn't allow computations with duplicate names.
      */
    void add_computation(computation *cpt);

    /**
      * Set the arguments of the function.
      * The arguments of the function are provided as a vector of
      * pointers to buffers. Each buffer represents an argument
      * to the function.
      * During code generation, the arguments in the vector will become
      * the arguments of the generated function (with the order of their
      * appearance in the vector).
      */
    void set_arguments(std::vector<tiramisu::buffer *> buffer_vec);

    /**
     * Set the context of the function. A context is an ISL set that
     * represents constraints over the parameters of the functions
     * (a parameter is an invariant variable for the function).
     * An example of a context set is the following:
     *          "[N,M]->{: M>0 and N>0}"
     * This context set indicates that the two parameters N and M
     * are strictly positive.
     */
    void set_context_set(std::string context_str);

    /**
      * This functions applies to the schedule of each computation
      * in the function.  It makes the dimensions of the ranges of
      * all the schedules equal.  This is done by adding dimensions
      * equal to 0 to the range of schedules.
      * This function is called automatically when gen_isl_ast()
      * or gen_time_processor_domain() are called.
      */
    void align_schedules();

    /**
      * Tag the dimension \p dim of the computation \p computation_name to
      * be parallelized.
      * The dimension 0 represents the outermost loop level (it
      * corresponds to the leftmost dimension in the iteration space).
      */
    void add_parallel_dimension(std::string computation_name, int vec_dim);

    /**
      * Tag the dimension \p dim of the computation \p computation_name to
      * be vectorized.
      * The dimension 0 represents the outermost loop level (it
      * corresponds to the leftmost dimension in the iteration space).
      */
    void add_vector_dimension(std::string computation_name, int vec_dim);

    /**
      * Tag the dimensions \p dim0 and \p dim1 of the computation
      * \p computation_name to be mapped to GPU.
      * The dimension 0 represents the outermost loop level (it
      * corresponds to the leftmost dimension in the iteration space).
      */
     void add_gpu_dimensions(std::string computation_name, int dim0, int dim1);

    /**
      * Set the iterator names of the function.
      * This function overrides any previously set iterator names.
      */
    void set_iterator_names(const std::vector<std::string>& iteratorNames);

    /**
      * Add an iterator to the function.
      */
    void add_iterator_name(const std::string iteratorName);

    /**
       * Generate an object file that contains the compiled function.
       * This function relies on Halide to generate the object file and
       * thus requires Halide objects as inputs.
       * \p obj_file_name indicates the name of the generated file.
       * \p os indicates the target operating system (Halide::Target::OS).
       * \p arch indicates the architecture of the target (the instruction set).
       * \p bits indicate the bit-width of the target machine.
       *    must be 0 for unknown, or 32 or 64.
       * For a full list of supported values for \p os and \p arch please
       * check the documentation of Halide::Target
       * (http://halide-lang.org/docs/struct_halide_1_1_target.html).
       * If the machine parameters are not supplied, Halide detects
       * the parameters of the host machine automatically.
       */
     // @{
     void gen_halide_obj(std::string obj_file_name, Halide::Target::OS os,
                         Halide::Target::Arch arch, int bits) const;

     void gen_halide_obj(std::string obj_file_name) const;
     // @}

     /**
       * Generate C code on stdout.
       * Currently C code code generation is very basic and does not
       * support many features compared to the Halide code generator.
       * Use this for debugging only.
       */
     void gen_c_code() const;

     /**
       * Generate an isl AST that represents the function.
       */
     void gen_isl_ast();

     /**
       * Generate a Halide stmt that represents the function.
       */
     void gen_halide_stmt();

     /**
       * Generate the time-processor domain of the function.
       * In this representation, the logical time of execution and the
       * processor where the computation will be executed are both
       * specified.
       */
     void gen_time_processor_domain();

    /**
      * Dump the iteration domain of the function.
      * This is mainly useful for debugging.
      */
    void dump_iteration_domain() const;

    /**
      * Dump the schedules of the computations of the function.
      * This is mainly useful for debugging.
      * The schedule is a relation between the iteration space and a
      * time space.  The relation provides a logical date of execution for
      * each point in the iteration space.
      * The schedule needs first to be set before calling this function.
      */
    void dump_schedule() const;

    /**
       * Dump (on stdout) the time processor domain of the function.
       * The time-processor domain should be generated before calling
       * this function (gen_time_processor_domain()).
       * This is mainly useful for debugging.
       */
     void dump_time_processor_domain() const;

     /**
       * Dump a Halide stmt that represents the function.
       * gen_halide_stmt should be called before calling this function.
       */
     void dump_halide_stmt() const;

    /**
      * Dump the function on standard output (dump most of the fields of
      * the function class).
      * This is mainly useful for debugging.
      * If \p exhaustive is set to true, all the fields of the function
      * class are printed.  This is useful for finding potential
      * initialization problems.
      */
    void dump(bool exhaustive) const;
};


/**
  * A class that represents buffers.
  * Buffers have two use cases:
  * - used to store the results of computations, and
  * - used to represent input arguments to functions.
  */
class buffer
{
private:
    /**
      * The name of the buffer.
      */
    std::string name;

    /**
      * The number of dimensions of the buffer.
      */
    int nb_dims;

    /**
      * The sizes of the dimensions of the buffer.  Assuming the following
      * buffer: buf[N0][N1][N2].  The first vector element represents the
      * size of rightmost dimension of the buffer (i.e. N2), the second
      * vector element is N1, and the last vector element is N0.
      */
    std::vector<tiramisu::expr> dim_sizes;

    /**
      * The type of the elements of the buffer.
      */
    tiramisu::primitive_t type;

    /**
      * Buffer data.
      */
    uint8_t *data;

    /**
      * The tiramisu function where this buffer is declared or where the
      * buffer is an argument.
      */
    tiramisu::function *fct;

    /**
     * Type of the argument (if the buffer is an argument):
     * Three possible types:
     *  - a_input: for inputs of the function,
     *  - a_output: for outputs of the function,
     *  - a_temporary: for buffers used as temporary buffers within
     *  the function (any temporary buffer is allocated automatically by
     *  the Tiramisu runtime at the entry of the function and is
     *  deallocated at the exit of the function).
     */
    tiramisu::argument_t argtype;

public:
    /**
      * Create a tiramisu buffer.
      * Buffers have two use cases:
      * - used to store the results of computations, and
      * - used to represent input arguments to functions.
      *
      * \p name is the name of the buffer.
      * \p nb_dims is the number of dimensions of the buffer.
      * A scalar is a one dimensional buffer that has a size of one
      * element.
      * \p dim_sizes is a vector of integers that represent the size
      * of each dimension in the buffer.  The first vector element
      * represents the rightmost array dimension, while the last vector
      * element represents the leftmost array dimension.
      * For example, in the buffer buf[N0][N1][N2], the first element
      * in the vector \p dim_sizes represents the size of rightmost
      * dimension of the buffer (i.e. N2), the second vector element
      * is N1, and the last vector element is N0.
      * Buffer dimensions in Tiramisu have the same semantics as in
      * C/C++.
      * \p type is the type of the elements of the buffer.
      * It must be a primitive type (i.e. p_uint8, p_uint16, ...).
      * Possible types are declared in tiramisu::primitive_t (type.h).
      * \p data is the data stored in the buffer.  This is useful
      * if an already allocated buffer is passed to Tiramisu.
      * \p fct is a pointer to a Tiramisu function where the buffer is
      * declared or used.
      * \p is_argument indicates whether the buffer is passed to the
      * function as an argument.  All the buffers passed as arguments
      * to the function should be allocated by the user outside the
      * function.  Buffers that are not passed to the function as
      * arguments are allocated automatically at the beginning of
      * the function and deallocated at the end of the function.
      * They are called temporary buffers (of type a_temporary).
      * Temporary buffers cannot be used outside the function
      * in which they were allocated.
      */
    buffer(std::string name, int nb_dims, std::vector<tiramisu::expr> dim_sizes,
           tiramisu::primitive_t type, uint8_t *data,
           tiramisu::argument_t argt, tiramisu::function *fct);

    /**
      * Return the type of the argument (if the buffer is an argument).
      * Three possible types:
      *  - a_input: for inputs of the function,
      *  - a_output: for outputs of the function,
      *  - a_temporary: for buffers used as temporary buffers within
      *  the function (any temporary buffer is allocated automatically by
      *  the Tiramisu runtime at the entry of the function and is
      *  deallocated at the exit of the function).
      */
    tiramisu::argument_t get_argument_type() const;

    /**
     * Return a pointer to the data stored within the buffer.
     */
    uint8_t *get_data();

    /**
      * Return the name of the buffer.
      */
    const std::string &get_name() const;

    /**
      * Get the number of dimensions of the buffer.
      */
    int get_n_dims() const;

    /**
    * Return the type of the elements of the buffer.
    */
    tiramisu::primitive_t get_type() const;

    /**
      * Return the sizes of the dimensions of the buffer.
      * Assuming the following buffer: buf[N0][N1][N2].  The first
      * vector element represents the size of rightmost dimension
      * of the buffer (i.e. N2), the second vector element is N1,
      * and the last vector element is N0.
      */
    const std::vector<tiramisu::expr> &get_dim_sizes() const;

    /**
      * Dump the function on standard output (dump most of the fields of
      * the buffer class).
      * This is mainly useful for debugging.
      * If \p exhaustive is set to true, all the fields of the buffer
      * class are printed.  This is useful to find potential initialization
      * problems.
      */
    void dump(bool exhaustive) const;
};



/**
  * A class that represents computations.
  * A computation is an expression associated with an iteration domain.
  * A computation indicates what needs to be computed (the expression
  * that should be computed).
  * A computation has three representations:
  * - Level 1: this level specifies "what" should be computed but does
  *   not specify "when" (order) and "where" (on which processor) each
  *   expression should be computed.
  *   This level also does not specify where computations should be stored
  *   in memory and in which data layout.
  * - Level 2: this level specifies "what" should be computed, "when", i.e.
  *   the order in which the computation should be executed with regard to
  *   the other computations. And "where" each computation should be
  *   computed (i.e., on which processor).
  *   This level still does not specify where computations should be stored
  *   in memory and their data layout.
  * - Level 3: this level is similar to Level 2 but it specifies where
  *   computations should be stored in memory and the data layout.
  */
class computation {
private:

    /**
      * An ISL context associate with the function.
      */
    isl_ctx *ctx;

    /**
      * Iteration domain of the computation.
      * In this representation, the order of execution of computations
      * is not specified, the computations are also not mapped to memory.
     */
    isl_set *iteration_domain;

    /**
      * Time-processor domain of the computation.
      * In this representation, the logical time of execution and the
      * processor where the computation will be executed are both
      * specified.
      */
    isl_set *time_processor_domain;

    /**
      * Schedule of the computation.
      */
    isl_map *schedule;

    /**
      * The function where this computation is declared.
      */
    tiramisu::function *function;

    /**
      * Halide statement that assigns the computation to a buffer location.
      */
    Halide::Internal::Stmt stmt;

    /**
      * Access function.  A map indicating how each computation should be stored
      * in memory.  It indicates in which buffer the computation should be stored
      * and which element of the buffer exactly it should be stored.
      */
    isl_map *access;

    /**
      * An isl_ast_expr representing the index of the array where the computation
      * will be stored.  This index is computed after the scheduling is done.
      */
    std::vector<isl_ast_expr *> index_expr;

    /**
     * Data type: the type of the value returned by the computation.
     */
    tiramisu::primitive_t data_type;

    /**
     * Update the name of the domain name of the schedule of a let statement.
     * If the computation is a let statement, and if the name of
     * the domain of map does not start with the LET_STMT_PREFIX,
     * add the LET_STMT_PREFIX to the name.
     * We use the LET_STMT_PREFIX to identify the computations that
     * represent a let statement.
     */
    isl_map* update_let_stmt_schedule_domain_name(isl_map* map);

    /**
     * A logical time that indicates the relative order of this computation
     * compared to other computations.
     * This should only be used by the .after() function and should not be
     * used directly by users.
     */
    unsigned long relative_order;

protected:

    /**
      * The name of this computation.
      */
    std::string name;

    /**
      * An expression representing the computation
      * ("what" should be computed).
      */
    tiramisu::expr expression;

    /**
     * TODO: use buffers directly from computations, no need to have
     * bindings.
     *
     * \p schedule_this_computation should be set to true when the computation
     * should be scheduled and when code for the computation should be generated
     * during code generation.
     * It should be set to false when the computation is used to represent a
     * buffer (i.e., the computation is used only as a binding to a buffer).
     * In this case, the computation is not scheduled and no code for the
     * computation is generated.
     */
    bool schedule_this_computation;

    /**
     * Does this computation represent a let statement ?
     * TODO: how is treating a computation that represents a let statement
     * different from treating normal computations ?
     */
    bool _is_let_stmt;

    /**
      * Initialize a computation.
      * This is a private function that should not be called explicitly
      * by users.
      */
    void init_computation(std::string iteration_space_str,
                          tiramisu::function *fct,
                          const tiramisu::expr &e,
                          bool schedule_this_computation,
                          tiramisu::primitive_t t);

    /**
     * Dummy constructor for derived classes.
     */
    computation();

public:

    /**
      * A number used to specify the dimension level known as root.
      * The root dimension level is the outermost level.  It is the level
      * outside any loop nest.  Loop level 0 is the level of the first loop
      * (outermost loop), loop 1 is the level of following inner loop, ...
      *
      * Where is this number used ?
      *
      * These numbers are used in the helper functions used for scheduling
      * (such as after(), before(), ...).
      * For example, c0.after(c1) indicates that the computation c0 should
      * be executed after the computation c1.
      * Since the two computations c0 and c1 are usually nested in a loop,
      * we need to specify at which loop level c0 is after c1. This is where
      * we need to specify the loop level numbers.
      * Here is an example.  Suppose that the two computations c0 and c1
      * have the following iteration domains
      * {c0[i,j]: 0<=i<N and 0<=j<N} and {c1[i,j]: 0<=i<N and 0<=j<N}.
      *
      * When code is generated for the two computations, two loop nests
      * are generated.  When scheduling c0 after c1 using the after function,
      * the user can choose one among three possibilities in specifying at
      * which level c0 is after c1.
      *
      * - c0.after(c1, computation::root_dimension) would create a schedule
      * that generates the following code
      *
      * for (i=0; i<N; i++)
      *     for (j=0; j<N; j++)
      *         c1;
      * for (i=0; i<N; i++)
      *     for (j=0; j<N; j++)
      *         c0;
      *
      * - c0.after(c1, 0) would create a schedule that generates the
      * following code
      *
      * for (i=0; i<N; i++) {
      *     for (j=0; j<N; j++)
      *         c1;
      *     for (j=0; j<N; j++)
      *         c0;
      * }
      *
      * This means that c0 is after c1 starting from loop level 0,
      * (before the loop level 0, c0 and c1 have the same order).
      *
      * - c0.after(c1, 1) would create a schedule that generates the
      * following code
      *
      * for (i=0; i<N; i++)
      *     for (j=0; j<N; j++) {
      *         c1;
      *         c0;
      *     }
      *
      * This means that c0 is after c1 starting from loop level 1,
      * (before the loop level 1, c0 and c1 have the same order).
      */
    const static int root_dimension = -1;

    /**
     * Let statements that should be computed before this computation.
     *
     * This is mainly useful when this computation consumes values
     * computed in let statements, so those let statements should
     * be executed before this computation.
     */
    tiramisu::computation *statements_to_compute_before_me;

    /**
      * Constructor for computations.
      *
      * \p iteration_domain_str is a string that represents the iteration
      * domain of the computation.  The iteration domain should be written
      * in the ISL format (http://isl.gforge.inria.fr/user.html#Sets-and-Relations).
      *
      * The iteration domain of a statement is a set that contains
      * all of the execution instances of the statement (a statement in a
      * loop has an execution instance for each loop iteration in which
      * it executes). Each execution instance of a statement in a loop
      * nest is uniquely represented by an identifier and a tuple of
      * integers  (typically,  the  values  of  the  outer  loop  iterators).
      *
      * For example, the iteration space of the statement S0 in the following
      * loop nest
      * for (i=0; i<2; i++)
      *   for (j=0; j<3; j++)
      *      S0;
      *
      * is {S0(0,0), S0(0,1), S0(0,2), S0(1,0), S0(1,1), S0(1,2)}
      *
      * S0(0,0) is the execution instance of S0 in the iteration (0,0).
      *
      * The previous set of integer tuples can be compactly described
      * by affine constraints as follows
      *
      * {S0(i,j): 0<=i<2 and 0<=j<3}
      *
      * In general, the loop nest
      *
      * for (i=0; i<N; i++)
      *   for (j=0; j<M; j++)
      *      S0;
      *
      * has the following iteration domain
      *
      * {S0(i,j): 0<=i<N and 0<=j<M}
      *
      * This should be read as: the set of points (i,j) such that
      * 0<=i<N and 0<=j<M.
      *
      * \p e is the expression computed by the computation.
      *
      * \p schedule_this_computation should be set to true if the computation
      * is supposed to be schedule and code is supposed to be generated from
      * the computation.  Set it to false if you just want to use the
      * computation to represent a buffer (that is passed as an argument
      * to the function) and you do not intend to generate code for the
      * computation.
      *
      * \p t is the type of the computation, i.e. the type of the expression
      * computed by the computation. Example of types include (p_uint8,
      * p_uint16, p_uint32, ...).
      *
      * \p fct is a pointer to the Tiramisu function where this computation
      * should be added.
      *
      * TODO: copy ISL format for sets.
      */
    computation(std::string iteration_domain_str, tiramisu::expr e,
                bool schedule_this_computation, tiramisu::primitive_t t,
                tiramisu::function *fct);

    /**
      * Return true if the this computation is supposed to be scheduled
      * by Tiramisu.
      */
    bool should_schedule_this_computation() const;

    /**
      * Return the access function of the computation.
      */
    isl_map *get_access() const;

    /**
      * Return the access function of the computation after transforming
      * it to the time-processor domain.
      * The domain of the access function is transformed to the
      * time-processor domain using the schedule, and then the transformed
      * access function is returned.
      */
      isl_map *get_access_transformed_to_time_processor_domain() const;

    /**
     * Return the Tiramisu expression associated with the computation.
     */
    const tiramisu::expr &get_expr() const;

    /**
      * Return the function where the computation is declared.
      */
    tiramisu::function *get_function() const;

    /**
      * Return vector of isl_ast_expr representing the indices of the array where
      * the computation will be stored.
      */
    std::vector<isl_ast_expr *> &get_index_expr();

    /**
      * Return the iteration domain of the computation.
      * In this representation, the order of execution of computations
      * is not specified, the computations are also not mapped to memory.
      */
    isl_set *get_iteration_domain() const;

    /**
      * Return the time-processor domain of the computation.
      * In this representation, the logical time of execution and the
      * processor where the computation will be executed are both
      * specified.
      */
    isl_set *get_time_processor_domain() const;

    /**
      * Return the schedule of the computation.
      */
    isl_map *get_schedule() const;

    /**
     * Return if this computation represents a let statement.
     */
    bool is_let_stmt() const;

    /**
      * Return the name of the computation.
      */
    const std::string &get_name() const;

    /**
      * Return the context of the computations.
      */
    isl_ctx *get_ctx() const;

    /**
     * Get the number of dimensions of the iteration
     * domain of the computation.
     */
    int get_n_dimensions();

    /**
     * Get the data type of the computation.
     */
    tiramisu::primitive_t get_data_type() const;

    /**
      * Return the Halide statement that assigns the computation to a buffer location.
      */
    Halide::Internal::Stmt get_halide_stmt() const;

    /**
     * Compare two computations.
     *
     * Two computations are considered to be equal if they have the
     * same name.
     */
    bool operator==(tiramisu::computation comp1);

    /**
     * Access operator: C0(i,j) represents an access to
     * the element (i,j) of the computation C0.
     * C0(i,j) represents the value computed by the computation
     * C0(i,j)
     *
     */
    template<typename... Args>
    tiramisu::expr operator()(Args... args)
    {
        std::vector<tiramisu::expr> access_expressions{std::forward<Args>(args)...};
        return tiramisu::expr(tiramisu::o_access,
                          tiramisu::expr(this->get_name()),
                          access_expressions,
                          this->get_data_type());
    }

    /**
      * Tag the dimension \p dim of the iteration space to be parallelized.
      *
      * The outermost loop level is 0 (it corresponds to the leftmost
      * dimension in the iteration domain).
      *
      * TODO: I think the following statement is wrong. It should be the
      * opposite.  It should be a dimension of the time-processor domain
      * not from the iteration domain because we are generating code from
      * the time-processor domain. Idem for tag_vector_dimension() and tag_gpu_dimensions().
      *
      * Note that \p dim is a dimension of the iteration domain
      * not a dimension of the time-processor domain.
      */
    void tag_parallel_dimension(int dim);

    /**
      * Tag the dimension \p dim of the iteration space to be vectorized.
      *
      * The outermost loop level is 0 (it corresponds to the leftmost
      * dimension in the iteration domain).
      *
      * Note that \p dim is a dimension of the iteration space
      * not a dimension of the time-processor space.
      *
      * The user can only tag dimensions that have constant extent as
      * to be vectorized.  If a loop dimension does not have a constant
      * extent, it first has to be split.
      */
    void tag_vector_dimension(int dim);

    /**
      * Tag the dimension \p dim0 and \p dim1 of the iteration domain to
      * be mapped to GPU.
      *
      * Note that \p dim0 and \p dim1 are dimensions of the iteration space
      * not dimensions of the time-processor space.
      *
      * The outermost loop level is 0 (it corresponds to the leftmost
      * dimension in the iteration domain).
      */
    void tag_gpu_dimensions(int dim0, int dim1);

    /**
      * Generate the time-processor domain of the computation.
      *
      * In this representation, the logical time of execution and the
      * processor where the computation will be executed are both
      * specified.  The memory location where computations will be
      * stored in memory is not specified at the level.
      */
    void gen_time_processor_domain();

    /**
      * Schedule this computation to run after the computation \p comp
      * at dimension \p dim of the time-processor domain.
      *
      * TODO: check how this works ? Is the root level dimension 0 as stated
      * here or it is root_level as stated in the documentation above.
      *
      * Use computation::root_dimension to indicate the root dimension
      * (i.e. the outermost time-processor dimension).
      * The first static dimension (dimensions used to specify the lexicographical order
      * in a given loop level) corresponds to dimension 0.
      * The first dynamic dimension (loop level dimension) corresponds to dimension 1.
      * Few assumptions about how you should call these functions:
        - Call .first() before calling any .after()
        - Call .after() in the order of appearance of stmts, that is
        if in the program you have S0, then S1 then S2, you should call
        .after() as follows:
              S1.after(S0, ...);
              S2.after(S1, ...);
         In this case, since S1 appears in the program before S2, we set S1 first
         then we set S2.
         but you should not call it as follows
              S2.after(S1, ...);
              S1.after(S0, ...);
         since this sets S2 and sets S1.
      */
    void after(computation &comp, int dim);

    /**
      * Schedule this computation to run first at dimension
      * \p dim of the time-processor space.
      *
      * Use computation::root_dimension to indicate the root dimension
      * (i.e. the outermost processor-time dimension).
      *
      * The outermost loop has a loop level equal to zero.
      */
    void first(int dim);

    /**
      * Schedule this computation to run before the computation \p comp
      * at dimension \p dim of the time-processor space.
      *
      * Use computation::root_dimension to indicate the root dimension
      * (i.e. the outermost processor-time dimension).
      *
      * The outermost loop has a loop level equal to zero.
      */
    void before(computation &comp, int dim);

    /**
     * Set the access function of the computation.
     *
     * The access function is a relation from computations to buffer locations.
     * \p access_str is a string that represents the relation (in ISL format,
     * http://isl.gforge.inria.fr/user.html#Sets-and-Relations).
     */
    void set_access(std::string access_str);

    /*
     * Create a Halide statement that assigns the computations to the memory
     * buffer and location specified by the access function.
     */
    void create_halide_assignment();

    /**
     * Generate an identity schedule for the computation.
     *
     * This identity schedule is an identity relation created from the iteration
     * domain.
     */
    isl_map *gen_identity_schedule_for_iteration_domain();

    /**
     * Generate an identity schedule for the computation.
     *
     * This identity schedule is an identity relation created from the
     * time-processor domain.
     */
    isl_map *gen_identity_schedule_for_time_space_domain();

    /**
     * Set an identity schedule for the computation.
     *
     * This identity schedule is an identity relation created from the iteration
     * domain.
     */
    void set_identity_schedule_based_on_iteration_domain();

    /**
      * Tile the two dimensions \p inDim0 and \p inDim1 with rectangular
      * tiling.  \p sizeX and \p sizeY represent the tile size.
      * \p inDim0 and \p inDim1 should be two consecutive dimensions
      * (i.e., \p inDim0 = \p inDim1 + 1) and they should satisfy
      * \p inDim0 > \p inDim1.
      */
    void tile(int inDim0, int inDim1, int sizeX, int sizeY);

    /**
     * Split the dimension \p inDim0 of the iteration space into two
     * new dimensions.
     * \p sizeX is the extent (size) of the inner loop created after
     * splitting.
     *
     * TODO: use iterator names instead of numbering.
     *
     * If you have a 2D loop with i and j as iterators
     * the dimension number of i is 1 and the dimension number of j is 3
     * and you want to split the dimension i by 16, you can call
     * s0.split(1, 16)
     * This will create two dimensions, let us call them i0 and i1,
     * the dimension number of i0 is 1 and
     * the dimension number of i1 is 3
     * the dimension number of j is now 5 instead of the old value 3.
     */
    void split(int inDim0, int sizeX);

    /**
     * Interchange (swap) the two dimensions \p inDim0 and \p inDim1.
     */
    void interchange(int inDim0, int inDim1);

    /**
      * Set the mapping from iteration space to time-processor space.
      * The name of the domain and range space must be identical.
      * The input string must be in the ISL map format.
      */
    void set_schedule(std::string map_str);

    /**
      * Set the schedule indicated by \p map.
      *
      * \p map is a string that represents a mapping from the iteration domain
      *  to the time-processor domain (the mapping is in the ISL format:
      *  http://isl.gforge.inria.fr/user.html#Sets-and-Relations).
      *
      * TODO: specify clearly the expected format for the schedule.
      *
      * The name of the domain and range space must be identical.
      */
    void set_schedule(isl_map *map);

    /**
     * Set the expression of the computation.
     */
    void set_expression(const tiramisu::expr &e);

    /**
      * Bind the computation to a buffer.
      * i.e. create a one-to-one data mapping between the computation
      * the buffer.
      */
    void bind_to(buffer *buff);

    /**
      * Dump the iteration domain of the computation.
      * This is useful for debugging.
      */
    void dump_iteration_domain() const;

    /**
      * Dump the schedule of the computation.
      * This is mainly useful for debugging.
      * The schedule is a relation between the iteration space and a
      * time space.  The relation provides a logical date of execution for
      * each point in the iteration space.
      * The schedule needs first to be set before calling this function.
      */
    void dump_schedule() const;

    /**
      * Dump (on stdout) the computation (dump most of the fields of the
      * computation class).
      * This is mainly useful for debugging.
      */
    void dump() const;
};


/**
  * A class that represents loop invariants.
  *
  * An object of the invariant class can be an expression, a symbolic constant
  * or a variable that is invariant to all the loops of the function.
  */
class constant: public computation
{
public:

    /**
      * Create a constant where \p param_name is the name of
      * the constant that will hold the value of the constant.
      *
      * \p param_expr is the expression that defines the value
      * of the constant.
      *
      * \p t indicates the type of the constant.
      *
      * \p function_wide should be set to true if the constant is
      * defined at the entry of the function and is visible to all
      * the computations.
      * If function_wide is set to true, then the constant is an
      * invariant to the whole function where it is declared.
      *
      * \p with_computation, should be set only if function_wide
      * is false, i.e. if the constant is not function wide.
      * In such a case the user should indicate where the
      * constant should be assigned.
      * \p with_computation indicates that the assignment should
      * be in the loop nest that computes the computation indicated by
      * \p with_computation at the dimension indicated
      * by \p at_iteration_space_dimension.
      * The root level (i.e. the level outer than any other loop level)
      * is computation::root_dimension.
      * 0 represents the first loop level and 1 represents the second
      * loop level, ...
      *
      * \p func is the function in which the constant is defined.
      */
    constant(std::string param_name, const tiramisu::expr &param_expr,
             tiramisu::primitive_t t,
             bool function_wide,
             tiramisu::computation *with_computation,
             int at_iteration_space_dimension,
             tiramisu::function *func);

    /**
      * Dump the invariant on standard output (dump most of the fields of
      * the invariant class).
      * This is mainly useful for debugging.
      * If \p exhaustive is set to true, all the fields of the invaraint
      * class are printed.  This is useful to find potential initialization
      * problems.
      */
    void dump(bool exhaustive) const;
};

// Halide IR specific functions

void halide_stmt_dump(Halide::Internal::Stmt s);

Halide::Internal::Stmt lower_halide_pipeline(const Halide::Target &t, Halide::Internal::Stmt s);

/**
 * TODO code cleaning:
 * - Fix the current ambiguities in the documentation (TODOs),
 * - Minimize public functions,
 * - Go to the tutorials, add a small explanation about how Tiramisu should work in general.
 * - Add two pages explaining how one should use Tiramisu,
 *
 * - Have documentation on header files only,
 * - Order the functions in the class computations (get functions then update functions ordered in alphabetical order),
 * - Clean/document expr.h and type.h
 */

}

#endif
